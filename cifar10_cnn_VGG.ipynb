{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd \n",
    "%matplotlib inline \n",
    "path_data = './data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torchvision.datasets.CIFAR10(root=path_data, train=True, download=True) \n",
    "test = torchvision.datasets.CIFAR10(root=path_data, train=False, download=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at `train`. What we get from this is a class called `CIFAR10`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.transform = cifar_transform\n",
    "test.transform = cifar_transform\n",
    "train.transforms = torchvision.datasets.vision.StandardTransform(cifar_transform)\n",
    "test.transforms = torchvision.datasets.vision.StandardTransform(cifar_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.transform)\n",
    "print('\\n######\\n')\n",
    "print(train.transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(train, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(train, batch_size=4,\n",
    "                                          shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = iter(trainloader)\n",
    "images, labels = train_iter.next()\n",
    "print(images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images, labels): \n",
    "    # normalise=True below shifts [-1,1] to [0,1]\n",
    "    img_grid = torchvision.utils.make_grid(images, nrow=4, normalize=True)\n",
    "    np_img = img_grid.numpy().transpose(1,2,0)  \n",
    "    plt.imshow(np_img)\n",
    "    \n",
    "d_class2idx = train.class_to_idx\n",
    "d_idx2class = dict(zip(d_class2idx.values(),d_class2idx.keys()))\n",
    "\n",
    "images, labels = train_iter.next()\n",
    "plot_images(images,labels)\n",
    "print(' '.join('%5s' % d_idx2class[int(labels[j])]for j in range(len(images))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "import torch.nn.functional as F "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{Wâˆ’K+2P}{S} +1$$\n",
    "\n",
    "- W is the input volume\n",
    "- K is the kernel size\n",
    "- P is the amount of padding\n",
    "- S is the stride size\n",
    "\n",
    "64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module): \n",
    "    def __init__(self): \n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3,padding=1) \n",
    "        self.conv3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3,padding=1) \n",
    "        self.conv4 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3,padding=1) \n",
    "        self.conv5 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3,padding=1) \n",
    "        self.conv6 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3,padding=1) \n",
    "        self.conv7 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3,padding=1) \n",
    "        self.conv8 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3,padding=1) \n",
    "        \n",
    "        # 5*5 comes from the dimension of the last convnet layer\n",
    "        self.fc1 = nn.Linear(512,512) \n",
    "        self.fc2 = nn.Linear(512,512)\n",
    "        self.fc3 = nn.Linear(512, 10)\n",
    "        \n",
    "    def forward(self, x): \n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool(F.relu(self.conv4(x)))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = self.pool(F.relu(self.conv6(x)))\n",
    "        x = F.relu(self.conv7(x))\n",
    "        x = self.pool(F.relu(self.conv8(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)  # no activation on final layer \n",
    "        return x\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable to save the value of the loss\n",
    "running_loss = 0 \n",
    "\n",
    "# print when the counter is divisible by this value\n",
    "printfreq = 1000\n",
    "\n",
    "# training loop\n",
    "num_epochs = 2\n",
    "for epoch in range(num_epochs):\n",
    "    for i, data in enumerate(trainloader):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)  # forward pass \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % printfreq == printfreq-1:  \n",
    "            print(\"Epoch: {}, Training Loss: {}\".format(epoch, running_loss / printfreq))\n",
    "            running_loss = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param_tensor in net.state_dict():\n",
    "    print(param_tensor, \"\\t\", net.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(optimizer.state_dict().keys())\n",
    "print(optimizer.state_dict()['param_groups'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = './models/CIFAR10_cnn.pth'\n",
    "torch.save(net.state_dict(), fname)\n",
    "loaded_dict = torch.load(fname)\n",
    "net.load_state_dict(loaded_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload net if needed\n",
    "fname = './models/CIFAR10_cnn.pth'\n",
    "loaded_dict = torch.load(fname)\n",
    "net.load_state_dict(loaded_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "{'airplane': 0, 'automobile': 1, 'bird': 2, 'cat': 3, 'deer': 4, 'dog': 5, 'frog': 6, 'horse': 7, 'ship': 8, 'truck': 9}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "plot_images(images,labels)\n",
    "print(' '.join('%5s' % d_idx2class[int(labels[j])]for j in range(len(images))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOGIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(images)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = outputs.argmax(dim=1)\n",
    "plot_images(images,preds)\n",
    "print(' '.join('%5s' % d_idx2class[int(preds[j])]for j in range(len(images))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class_correct = list(0 for i in range(10))  # Holds how many correct images for the class\n",
    "class_total = list(0 for i in range(10))  # Holds total images for the class \n",
    "\n",
    "with torch.no_grad(): \n",
    "    for i, data in enumerate(testloader): \n",
    "        images, labels = data \n",
    "        outputs = net(images) \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels)\n",
    "        for j in range(4): \n",
    "            label = labels[j]\n",
    "            class_correct[label] += c[j].item()\n",
    "            class_total[label] += 1\n",
    "            \n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        d_idx2class[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sam import SAM"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "base_optimizer = torch.optim.SGD  # define an optimizer for the \"sharpness-aware\" update\n",
    "optimizer = SAM(net.parameters(), base_optimizer, lr=0.1, momentum=0.9)\n",
    "\n",
    "for input, output in data:\n",
    "\n",
    "  # first forward-backward pass\n",
    "  loss = loss_function(output, model(input))  # use this loss for any training statistics\n",
    "  loss.backward()\n",
    "  optimizer.first_step(zero_grad=True)\n",
    "  \n",
    "  # second forward-backward pass\n",
    "  loss_function(output, model(input)).backward()  # make sure to do a full forward pass\n",
    "  optimizer.second_step(zero_grad=True)\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From SAM paper: https://arxiv.org/abs/2010.01412\n",
    "base_optimizer = torch.optim.SGD  # define an optimizer for the \"sharpness-aware\" update\n",
    "optimizer = SAM(net.parameters(), base_optimizer, lr=0.1, momentum=0.9)\n",
    "\n",
    "\n",
    "# variable to save the value of the loss\n",
    "running_loss = 0 \n",
    "\n",
    "# print when the counter is divisible by this value\n",
    "printfreq = 1000\n",
    "\n",
    "# training loop\n",
    "num_epochs = 2\n",
    "for epoch in range(num_epochs):\n",
    "    for i, data in enumerate(trainloader):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # first forward-backward pass \n",
    "        outputs = net(inputs)  # forward pass \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.first_step(zero_grad=True)\n",
    "        \n",
    "        # second forward-backward pass\n",
    "        outputs = net(inputs)  # forward pass \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.second_step(zero_grad=True)\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i % printfreq == printfreq-1:  \n",
    "            print(\"Epoch: {}, Training Loss: {}\".format(epoch, running_loss / printfreq))\n",
    "            running_loss = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
