{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "id": "2svevXfLgBvL"
   },
   "source": [
    "!pip install simpleitk\n",
    "\n",
    "# Mindboggle-101 volume dataset\n",
    "# Klein, Arno, 2016, \"Mindboggle-101 manually labeled individual brains\", https://doi.org/10.7910/DVN/HMQKCK, Harvard Dataverse, V2\n",
    "!mkdir dataverse_files\n",
    "!wget -O dataverse_files/NKI-RS-22_volumes.tar.gz https://dataverse.harvard.edu/api/access/datafile/:persistentId?persistentId=doi:10.7910/DVN/HMQKCK/BLM31U\n",
    "!wget -O dataverse_files/OASIS-TRT-20_volumes.tar.gz https://dataverse.harvard.edu/api/access/datafile/:persistentId?persistentId=doi:10.7910/DVN/HMQKCK/GSINRF\n",
    "!wget -O dataverse_files/MMRR-21_volumes.tar.gz https://dataverse.harvard.edu/api/access/datafile/:persistentId?persistentId=doi:10.7910/DVN/HMQKCK/ISG4EL\n",
    "!wget -O dataverse_files/NKI-TRT-20_volumes.tar.gz https://dataverse.harvard.edu/api/access/datafile/:persistentId?persistentId=doi:10.7910/DVN/HMQKCK/XHCJPK\n",
    "!wget -O dataverse_files/Extra-18_volumes.tar.gz https://dataverse.harvard.edu/api/access/datafile/:persistentId?persistentId=doi:10.7910/DVN/HMQKCK/8FEQZI\n",
    "\n",
    "!tar xzf dataverse_files/NKI-RS-22_volumes.tar.gz -C dataverse_files/\n",
    "!tar xzf dataverse_files/OASIS-TRT-20_volumes.tar.gz -C dataverse_files/\n",
    "!tar xzf dataverse_files/MMRR-21_volumes.tar.gz -C dataverse_files/\n",
    "!tar xzf dataverse_files/NKI-TRT-20_volumes.tar.gz -C dataverse_files/\n",
    "!tar xzf dataverse_files/Extra-18_volumes.tar.gz -C dataverse_files/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xuiYOYhZf0SY"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"GPU available:\", tf.test.is_gpu_available())\n",
    "\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK as sitk\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "\n",
    "def display(display_list, cmap='bone'):\n",
    "    plt.figure(figsize=(9, 9))\n",
    "\n",
    "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i + 1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]), cmap=cmap)\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def create_mask(pred_mask):\n",
    "    # pred_mask = tf.argmax(pred_mask, axis=-1)\n",
    "    # pred_mask = pred_mask[..., tf.newaxis]\n",
    "    pred_mask[pred_mask > 0] = 1\n",
    "    pred_mask[pred_mask < 0] = 0\n",
    "    return pred_mask[0]\n",
    "\n",
    "\n",
    "def show_predictions(dataset=None, num=1):\n",
    "    if dataset:\n",
    "        for image, mask in dataset.take(num):\n",
    "            pred_mask = model.predict(image)\n",
    "            display([image[0], mask[0], create_mask(pred_mask)])\n",
    "    else:\n",
    "        display([sample_image, sample_mask, create_mask(model.predict(sample_image[tf.newaxis, ...]))])\n",
    "\n",
    "\n",
    "\n",
    "class DisplayCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        show_predictions()\n",
    "        print(f'\\nSample Prediction after epoch {epoch + 1}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K2WWPsWKtx0q"
   },
   "outputs": [],
   "source": [
    "def downsample_block(inputs, filters, size):\n",
    "    x = layers.Conv2D(filters, size, padding='same')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv2D(filters, size, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    y = layers.ReLU()(x)\n",
    "\n",
    "    x = layers.MaxPool2D()(y)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def upsample_block(inputs, inputs_skip, filters, size):\n",
    "    x = layers.Conv2DTranspose(filters, size, strides=2, padding='same')(inputs)\n",
    "    x = layers.Concatenate()([x, inputs_skip])\n",
    "    x = layers.Conv2D(filters, size, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv2D(filters, size, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def bottom_block(inputs, filters, size):\n",
    "    x = layers.Conv2D(filters, size, padding='same')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Conv2D(filters, size, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def unet_model(input_shape):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "    x, skip1 = downsample_block(inputs, 64, 3)\n",
    "    x, skip2 = downsample_block(x, 128, 3)\n",
    "    x, skip3 = downsample_block(x, 256, 3)\n",
    "    x, skip4 = downsample_block(x, 512, 3)\n",
    "\n",
    "    x = bottom_block(x, 1024, 3)\n",
    "\n",
    "    x = upsample_block(x, skip4, 512, 3)\n",
    "    x = upsample_block(x, skip3, 256, 3)\n",
    "    x = upsample_block(x, skip2, 128, 3)\n",
    "    x = upsample_block(x, skip1, 64, 3)\n",
    "\n",
    "    output = layers.Conv2D(1, 3, padding='same')(x)\n",
    "\n",
    "    out_model = tf.keras.Model(inputs, output, name='Unet')\n",
    "\n",
    "    return out_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ICkz2IaoDCge"
   },
   "outputs": [],
   "source": [
    "def label_map_3(seg_2d, img_2d):\n",
    "    # works for 3d input image\n",
    "    # 0 is white matter\n",
    "    mask_image[mask_image == 1035] = 0 # set the insula as background\n",
    "    mask_image[mask_image == 2035] = 0\n",
    "    mask_image[mask_image != 0] = 1  # gray matter\n",
    "    mask_image[mask_image == 0] = 2  # background\n",
    "    return mask_image\n",
    "\n",
    "def label_map_dkt31_6(seg_2d):\n",
    "    # works for 3d input image\n",
    "    # 0: white matter & background\n",
    "    # 2,3: TEMPORAL_LOBE_MEDIAL\n",
    "    TEMPORAL_LOBE_MEDIAL = {6, 16, 7}\n",
    "    # 4,5: TEMPORAL_LOBE_LATERAL\n",
    "    TEMPORAL_LOBE_LATERAL = {30, 15, 9, 34}\n",
    "    # 6,7: FRONTAL_LOBE\n",
    "    FRONTAL_LOBE = {28, 12, 14, 24, 17, 3, 18, 19, 20, 27}\n",
    "    # 8,9: PARIETAL_LOBE\n",
    "    PARIETAL_LOBE = {22, 31, 29, 8, 25}\n",
    "    # 10, 11: OCCIPITAL_LOBE\n",
    "    OCCIPITAL_LOBE = {13, 21, 5, 11}\n",
    "    # 12, 13: CINGULATE_CORTEX\n",
    "    CINGULATE_CORTEX = {10, 23, 26, 2}\n",
    "    # removed #35\n",
    "    label_cluster = [TEMPORAL_LOBE_MEDIAL, TEMPORAL_LOBE_LATERAL, FRONTAL_LOBE, PARIETAL_LOBE, OCCIPITAL_LOBE, CINGULATE_CORTEX]\n",
    "    def get_new_label(old_label, left_right):\n",
    "        for idx, lobe in enumerate(label_cluster):\n",
    "            if old_label in lobe:\n",
    "                if left_right == \"left\":\n",
    "                    return 2+2*idx\n",
    "                elif left_right == \"right\":\n",
    "                    return 3+2*idx\n",
    "                else:\n",
    "                    raise ValueError(\"Wrong left_right value!\")\n",
    "        return 0\n",
    "\n",
    "    seg_shape = seg_2d.shape\n",
    "    seg_1d = seg_2d.flatten()\n",
    "    for idx, val in enumerate(seg_1d):\n",
    "        val = int(val)\n",
    "        if val == 0:\n",
    "            continue\n",
    "        elif 1002 <= val <= 1035:\n",
    "            seg_1d[idx] = get_new_label(val-1000, \"left\")\n",
    "        elif 2002 <= val <= 2035:\n",
    "            seg_1d[idx] = get_new_label(val-2000, \"right\")\n",
    "        else:\n",
    "            seg_1d[idx] = 0\n",
    "            \n",
    "            # raise ValueError(\"Could not convert label number {} for brain segmentation\".format(val))\n",
    "    seg_2d = seg_1d.reshape(seg_shape)\n",
    "    return seg_2d\n",
    "\n",
    "extra_mask = None\n",
    "temp_arr_inp = []\n",
    "temp_arr_label = []\n",
    "\n",
    "def load_whole_brain_seg_data(set_start: int, set_end: bool, structures: bool, base_raw: bool,\n",
    "                              mni152: bool, structures_cortex: bool,\n",
    "                              resize: bool, resize_shape: [int, int, int],\n",
    "                              augment: bool, augment_only_images: bool):\n",
    "    datadirpath = 'dataverse_files'\n",
    "    datasetpath_dic = {\n",
    "        'NKI-RS': 'NKI-RS-22_volumes',\n",
    "        'OASIS-TRT': 'OASIS-TRT-20_volumes',\n",
    "        'MMRR': 'MMRR-21_volumes',\n",
    "        'NKI-TRT': 'NKI-TRT-20_volumes',\n",
    "        'Extra': 'Extra-18_volumes'\n",
    "    }\n",
    "\n",
    "    if set_start == 0 and set_end == 0:\n",
    "        dataset_list = list(datasetpath_dic.values())\n",
    "    else:\n",
    "        dataset_list = list(datasetpath_dic.values())[set_start:set_end]\n",
    "\n",
    "    print('dataset_list',dataset_list)\n",
    "\n",
    "    scan_file_name = 't1weighted'\n",
    "    if not base_raw:\n",
    "        scan_file_name = scan_file_name + '_brain'\n",
    "\n",
    "    if structures:\n",
    "        mask_file_name = 'labels.DKT31.manual+aseg'\n",
    "    else:\n",
    "        mask_file_name = 't1weighted_brain'\n",
    "\n",
    "    if mni152:\n",
    "        scan_file_name = scan_file_name + '.MNI152'\n",
    "        mask_file_name = mask_file_name + '.MNI152'\n",
    "\n",
    "    scan_file_name = scan_file_name + '.nii.gz'\n",
    "    mask_file_name = mask_file_name + '.nii.gz'\n",
    "\n",
    "    for dataset in dataset_list:\n",
    "        dataset_path = os.path.join(datadirpath, dataset)\n",
    "        dir_list = [x for x in os.listdir(dataset_path) if '-' in x]\n",
    "#         print('dir_list',dir_list)\n",
    "        i=0\n",
    "        for directory in dir_list:\n",
    "            raw_scan_file = os.path.join(dataset_path, directory, scan_file_name)\n",
    "            brain_scan_file = os.path.join(dataset_path, directory, mask_file_name)\n",
    "            print(\"raw_scan_file\",raw_scan_file)\n",
    "            print(\"brain_scan_file\",brain_scan_file)\n",
    "\n",
    "            scan_image = sitk.GetArrayFromImage(sitk.ReadImage(raw_scan_file, sitk.sitkFloat32))#.nii.gz to npy\n",
    "            scan_image /= np.amax(scan_image) #normalization\n",
    "\n",
    "            mask_image = sitk.GetArrayFromImage(sitk.ReadImage(brain_scan_file, sitk.sitkFloat32))\n",
    "            \n",
    "            # make mask label to 13 classes.\n",
    "            extra_mask = label_map_dkt31_6(mask_image)\n",
    "            for i in range(1,3):\n",
    "                temp_arr_inp.append(scan_image)\n",
    "                temp_arr_label.append(mask_image)\n",
    "            \n",
    "#             if i==0:\n",
    "#                 print(\"::::::::::::::::::\")\n",
    "#                 print(mask_image.min())\n",
    "#                 print(mask_image.max())\n",
    "#                 print(np.unique(mask_image))\n",
    "                \n",
    "                \n",
    "#                 print(\"extra mask\")\n",
    "#                 print(extra_mask.min())\n",
    "#                 print(extra_mask.max())\n",
    "#                 print(np.unique(extra_mask))\n",
    "                \n",
    "#                 print(\"::::::::::::::::::\")\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "#             i+=1\n",
    "\n",
    "\n",
    "            # make mask label binary (0 and 1)\n",
    "            if not structures:\n",
    "                mask_image = np.where(0 == mask_image, mask_image, 1)\n",
    "            \n",
    "            # multilabel ???\n",
    "            \n",
    "            \"\"\"\n",
    "            \n",
    "            \"\"\"\n",
    "            \n",
    "            if structures and not structures_cortex:\n",
    "                mask_image = np.where(2000.0 > mask_image, mask_image, mask_image - 1000.0)\n",
    "                mask_image = np.where(1000.0 > mask_image, mask_image, mask_image - 1000.0)\n",
    "\n",
    "            if resize:\n",
    "#                 print('scan_image',scan_image.shape) #[182,218,182]\n",
    "#                 print('mask_image',mask_image.shape)\n",
    "                scan_image = resize_256(scan_image, resize_shape)\n",
    "                mask_image = resize_256(mask_image, resize_shape)\n",
    "#                 print('scan_image',scan_image.shape)\n",
    "#                 print('mask_image',mask_image.shape) #[182,256,256] after reshape\n",
    "\n",
    "            if augment:\n",
    "                scan_image, mask_image = image_augmentation(scan_image, mask_image, augment_only_images)\n",
    "\n",
    "            scan_image = np.expand_dims(scan_image, axis=-1)\n",
    "            mask_image = np.expand_dims(mask_image, axis=-1)\n",
    "\n",
    "            for slices in range(len(scan_image)):\n",
    "                yield scan_image[slices], mask_image[slices]\n",
    "        \n",
    "        print('Loaded ' + dataset)\n",
    "#         print('temp_arr_inp',temp_arr_inp)\n",
    "\n",
    "\n",
    "def resize_256(array, resize_shape: [int, int, int]) -> np.array:\n",
    "    for dim in range(len(resize_shape)):\n",
    "        if resize_shape[dim] == 0:\n",
    "            resize_shape[dim] = array.shape[dim]\n",
    "    shape_dif = np.subtract(resize_shape, array.shape) #[0,38,74]\n",
    "\n",
    "    # Padding\n",
    "    pad_list = []\n",
    "    for dif in shape_dif:\n",
    "        if dif <= 0:\n",
    "            pad_list.append([0, 0])\n",
    "        elif dif % 2 != 0:\n",
    "            pad = int((dif - 1) / 2)\n",
    "            pad_list.append([pad, pad + 1])\n",
    "        else:\n",
    "            pad = int(dif / 2)\n",
    "            pad_list.append([pad, pad])\n",
    "\n",
    "    output_array = np.pad(array, pad_list, mode='constant', constant_values=0.0)\n",
    "\n",
    "    # Cropping\n",
    "    cl = []  # crop_list\n",
    "    for dif in shape_dif:\n",
    "        if dif >= 0:\n",
    "            cl.append([0, 256])\n",
    "        elif dif % 2 != 0:\n",
    "            crop = abs(int((dif + 1) / 2))\n",
    "            cl.append([crop, crop + 256])\n",
    "        else:\n",
    "            crop = abs(int(dif / 2))\n",
    "            cl.append([crop, crop + 256])\n",
    "\n",
    "    output_array = output_array[cl[0][0]:cl[0][1], cl[1][0]:cl[1][1], cl[2][0]:cl[2][1]]\n",
    "\n",
    "    return output_array\n",
    "\n",
    "\n",
    "def image_augmentation(scan_image, mask_image, augment_only_images=True):\n",
    "    rng = np.random.default_rng()\n",
    "\n",
    "    if augment_only_images:\n",
    "        scan = scan_image\n",
    "        mask = mask_image\n",
    "        for index in range(len(scan_image)):\n",
    "            if bool(rng.integers(2, size=1)[0]):\n",
    "                scan[index] = np.transpose(scan[index], [1, 0])\n",
    "                mask[index] = np.transpose(mask[index], [1, 0])\n",
    "    else:\n",
    "        tranpose_array = [0, 1, 2]\n",
    "        rng.shuffle(tranpose_array)\n",
    "\n",
    "        scan = np.transpose(scan_image, tranpose_array)\n",
    "        mask = np.transpose(mask_image, tranpose_array)\n",
    "\n",
    "    for index in range(len(scan_image)):\n",
    "        if bool(rng.integers(2, size=1)[0]):\n",
    "            scan[index] = np.flip(scan[index], axis=0)\n",
    "            mask[index] = np.flip(mask[index], axis=0)\n",
    "\n",
    "        if bool(rng.integers(2, size=1)[0]):\n",
    "            scan[index] = np.flip(scan[index], axis=1)\n",
    "            mask[index] = np.flip(mask[index], axis=1)\n",
    "\n",
    "    return scan, mask\n",
    "\n",
    "\n",
    "dim1 = 256\n",
    "dim2 = 256\n",
    "\n",
    "structures = False\n",
    "base_raw = True\n",
    "mni152 = True\n",
    "structures_cortex = False\n",
    "resize = True\n",
    "resize_shape = [0, dim1, dim2]\n",
    "augment = True\n",
    "augment_only_images = True\n",
    "\n",
    "# args = [set_start, set_end, structures, base_raw, mni152, structures_cortex, resize, resize_shape, augment, augment_only_images]\n",
    "\n",
    "#tf.data.Dataset.from_generator for data pipeline.helps to create source datset from input data,apply transformations and preprocess \n",
    "#to iterate over dataset\n",
    "\n",
    "train_ds = tf.data.Dataset.from_generator(load_whole_brain_seg_data,\n",
    "                                    args=[0, 3, structures, base_raw, mni152, structures_cortex, resize, resize_shape, augment, augment_only_images],\n",
    "                                    output_signature=(\n",
    "                                        tf.TensorSpec(shape=(dim1, dim2, 1), dtype=tf.float32),\n",
    "                                        tf.TensorSpec(shape=(dim1, dim2, 1), dtype=tf.float32)))\n",
    "\n",
    "val_ds = tf.data.Dataset.from_generator(load_whole_brain_seg_data,\n",
    "                                    args=[3, 4, structures, base_raw, mni152, structures_cortex, resize, resize_shape, augment, augment_only_images],\n",
    "                                    output_signature=(\n",
    "                                        tf.TensorSpec(shape=(dim1, dim2, 1), dtype=tf.float32),\n",
    "                                        tf.TensorSpec(shape=(dim1, dim2, 1), dtype=tf.float32)))\n",
    "\n",
    "\n",
    "test_ds = tf.data.Dataset.from_generator(load_whole_brain_seg_data,\n",
    "                                    args=[4, 5, structures, base_raw, mni152, structures_cortex, resize, resize_shape, augment, augment_only_images],\n",
    "                                    output_signature=(\n",
    "                                        tf.TensorSpec(shape=(dim1, dim2, 1), dtype=tf.float32),\n",
    "                                        tf.TensorSpec(shape=(dim1, dim2, 1), dtype=tf.float32)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_z2PtId0gZ-V"
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "\n",
    "def performance(ds):\n",
    "    ds = ds.cache()\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "train_ds = train_ds.shuffle(10000)\n",
    "val_ds = val_ds.shuffle(10000)\n",
    "\n",
    "train_ds = performance(train_ds)\n",
    "train_ds = train_ds.repeat()\n",
    "val_ds = performance(val_ds)\n",
    "test_ds = performance(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, mask in train_ds.take(1):\n",
    "    display([image[0], mask[0]])\n",
    "    sample_image, sample_mask = image[0], mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 389
    },
    "id": "MRyhpxyvhYUw",
    "outputId": "d01df864-39fb-40af-ff0b-ee6ef2611309"
   },
   "outputs": [],
   "source": [
    "# print(train_ds)\n",
    "# print(val_ds)\n",
    "# print(train_ds.cardinality())\n",
    "# print(val_ds.cardinality())\n",
    "\n",
    "# for image, mask in test_ds.take(1):\n",
    "#     sample_image, sample_mask = image[0], mask[0]\n",
    "#     tranpose_array = [0, 1, 2]\n",
    "# #     rng.shuffle(tranpose_array)\n",
    "#     print(image.shape)\n",
    "#     display(sample_image[np.newaxis,...])\n",
    "#     scan = np.transpose(image[0], tranpose_array)\n",
    "#     print(\"scan\",scan.shape)\n",
    "#     display(scan[np.newaxis,...])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "image, mask = test_ds.take(1)\n",
    "# plt.imshow(tf.keras.preprocessing.image.array_to_img(image[0]), cmap='bone')\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(test_ds.take(1).yield())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x = [182,256,256]\n",
    "y = [182,218,182]\n",
    "len(x)\n",
    "for dim in range(len(x)):\n",
    "    print(x[dim])\n",
    "shape_dif = np.subtract(x, y)\n",
    "shape_dif"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mask_out = np.where(2000.0 > mask[0], mask[0], mask[0] - 1000.0)\n",
    "mask_out = np.where(1000.0 > mask[0], mask[0], mask[0] - 1000.0)\n",
    "\n",
    "np.unique(mask_out)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mask.numpy().min()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mask.numpy().max()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "np.unique(mask.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "image.numpy().max()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "image.numpy().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, mask in train_ds.take(1):\n",
    "    display([image[0], mask[0]])\n",
    "    sample_image, sample_mask = image[0], mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9pp_CguFh-D8",
    "outputId": "62770a37-43e7-4a69-a05e-7fa17a971f3c"
   },
   "outputs": [],
   "source": [
    "model = unet_model((dim1, dim2, 1))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0001)\n",
    "model.compile(optimizer=optimizer, loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "\n",
    "epochs = 20\n",
    "steps_per_epoch = 256\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "checkpoint_filepath = 'epochmodels/{epoch:02d}-' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "model_save_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath, save_freq=steps_per_epoch * 4)\n",
    "\n",
    "model_history = model.fit(train_ds, epochs=epochs,\n",
    "                          steps_per_epoch=steps_per_epoch,\n",
    "                          validation_data=val_ds,\n",
    "                          callbacks=[DisplayCallback(), tensorboard_callback, earlystop_callback, model_save_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "id": "RadWaL7T96Ky",
    "outputId": "93b5795b-aa2c-4b94-b437-bdf83622cfe7"
   },
   "outputs": [],
   "source": [
    "acc = model_history.history['accuracy']\n",
    "val_acc = model_history.history['val_accuracy']\n",
    "loss = model_history.history['loss']\n",
    "val_loss = model_history.history['val_loss']\n",
    "\n",
    "epochs_range = range(0, epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='lower left')\n",
    "plt.title('Loss')\n",
    "\n",
    "plt.suptitle(f'brainseg_whole_210303_6\\nBatch size: {batch_size}, Epochs: {epochs}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "VaNV2UsPr779",
    "outputId": "df281ba3-2aee-40e9-a083-62684ee93960"
   },
   "outputs": [],
   "source": [
    "show_predictions(test_ds, num=10)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "iJ_umvaYFuJl"
   },
   "source": [
    "# Export\n",
    "# !zip -r /content/savedmodel.zip /content/epochmodels/\n",
    "# !zip -r /content/logs.zip /content/logs"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4AooZa8_FjfS",
    "outputId": "0d3ddb94-75a9-45df-c079-1117903cb356"
   },
   "source": [
    "save_path = 'epochmodels/15-20210303-235240'\n",
    "model.save(save_path)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "DxeqiMKx3kNP"
   },
   "source": [
    "# !rm -rf ./logs/\n",
    "# !rm -rf ./epochmodels/"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "wA8yUSGYCot_"
   },
   "source": [
    "# !rm savedmodel.zip\n",
    "# !rm logs.zip"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "unet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
